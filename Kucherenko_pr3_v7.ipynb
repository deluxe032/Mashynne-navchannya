{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a283c7e4",
   "metadata": {},
   "source": [
    "# Лабораторна робота 3. Машинне навчання — Лінійна регресія\n",
    "**Підготовлено:** Кучеренко Іван  \n",
    "**Варіант:** 7\n",
    "\n",
    "Файл містить два завдання:\n",
    "- Завдання 1: Diabetes Dataset — попередній аналіз, побудова моделей LinearRegression та RandomForestRegressor.\n",
    "- Завдання 2: Housing dataset (файл `house_price_regression_dataset.csv`) — попередній аналіз, побудова моделей LinearRegression, RandomForestRegressor та Ridge з підбором гіперпараметрів.\n",
    "\n",
    "У кожному завданні код містить кроки: зчитування/огляд даних, обробка пропусків, видалення дублікатів, масштабування, розбиття на трен/тест, навчання моделей, оцінка (R², MSE), графіки та висновок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186900a9",
   "metadata": {},
   "source": [
    "## Завдання 1 — Diabetes Dataset\n",
    "**Кроки:** 1) Зчитати датасет; 2) Аналіз даних; 3) Обробка; 4) Кореляція; 5) Масштабування; 6) Розбиття; 7) Навчання LinearRegression та RandomForest; 8) Оцінка; 9) Графіки; 10) Висновок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a53835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Завдання 1 — Diabetes Dataset\n",
    "# 1. Імпорт бібліотек та завантаження датасету\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Завантажуємо датасет\n",
    "diab = load_diabetes(as_frame=True)\n",
    "X = diab.data\n",
    "y = diab.target\n",
    "df = pd.concat([X, y.rename(\"target\")], axis=1)\n",
    "\n",
    "# 1. Перші 5 рядків\n",
    "print(\"Перші 5 рядків датасету Diabetes:\")\n",
    "display(df.head())\n",
    "\n",
    "# 2. Перевірка на пропуски\n",
    "print(\"\\nКількість пропусків по стовпцях:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Запис: у цьому датасеті пропусків немає, але на випадок - заповнимо середнім (загальний шаблон)\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# 3. Перевірка дублікатів\n",
    "dups = df.duplicated().sum()\n",
    "print(f\"\\nКількість дублікатів: {dups}\")\n",
    "if dups > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Дублікат(и) видалено.\")\n",
    "\n",
    "# 4. Перевірка бінарних ознак (стать) — у diabetes стандартних label'ів немає, але перевіримо уявлення\n",
    "print(\"\\nОригінальні колонки:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# (У цьому датасеті 'sex' є нормалізованою числовою ознакою; для безпечності перевіримо унікальні значення)\n",
    "if 'sex' in df.columns:\n",
    "    print(\"\\nУнікальні значення 'sex':\", df['sex'].unique())\n",
    "\n",
    "# 5. Типи даних\n",
    "print(\"\\nТипи даних:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 6. Кореляція з цільовою змінною (прогрес діабету)\n",
    "corrs = df.corr()['target'].drop('target').abs().sort_values(ascending=False)\n",
    "print(\"\\nКореляція ознак з target (у порядку спадання):\")\n",
    "display(corrs)\n",
    "\n",
    "# Побудуємо теплову карту кореляцій (всіх змінних)\n",
    "plt.figure(figsize=(10,8))\n",
    "corr_matrix = df.corr()\n",
    "plt.imshow(corr_matrix, cmap='coolwarm', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(corr_matrix.index)), corr_matrix.index)\n",
    "plt.title('Теплова карта кореляцій (Diabetes)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Масштабування ознак\n",
    "features = df.drop(columns=['target']).columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "# 8. Розбиття на тренувальну і тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 9. Вибір найбільш корельованих ознак (візьмемо top-5)\n",
    "top_k = 5\n",
    "top_features = corrs.head(top_k).index.tolist()\n",
    "print(f\"\\nВибрані {top_k} найбільш корельованих ознак:\", top_features)\n",
    "\n",
    "X_train_sel = X_train[top_features]\n",
    "X_test_sel = X_test[top_features]\n",
    "\n",
    "# Навчання моделей\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "lr.fit(X_train_sel, y_train)\n",
    "rf.fit(X_train_sel, y_train)\n",
    "\n",
    "# 10. Оцінка\n",
    "y_pred_lr = lr.predict(X_test_sel)\n",
    "y_pred_rf = rf.predict(X_test_sel)\n",
    "\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nLinear Regression: R2 = {:.4f}, MSE = {:.4f}\".format(r2_lr, mse_lr))\n",
    "print(\"Random Forest:     R2 = {:.4f}, MSE = {:.4f}\".format(r2_rf, mse_rf))\n",
    "\n",
    "# 11. Графіки: справжні vs прогнозовані\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(y_test, y_pred_lr, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.xlabel('True target')\n",
    "plt.ylabel('Predicted (LR)')\n",
    "plt.title('True vs Predicted — LinearRegression')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.xlabel('True target')\n",
    "plt.ylabel('Predicted (RF)')\n",
    "plt.title('True vs Predicted — RandomForest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Графік залишків для кращого розуміння\n",
    "res_lr = y_test - y_pred_lr\n",
    "res_rf = y_test - y_pred_rf\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(y_pred_lr, res_lr, alpha=0.7)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Predicted (LR)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals — LinearRegression')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(y_pred_rf, res_rf, alpha=0.7)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Predicted (RF)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals — RandomForest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 12. Вивести справжні і прогнозовані значення (перші 10)\n",
    "results = pd.DataFrame({\n",
    "    'True': y_test.values,\n",
    "    'Pred_LR': y_pred_lr,\n",
    "    'Pred_RF': y_pred_rf\n",
    "}).reset_index(drop=True)\n",
    "print(\"\\nПерші 10 рядків: справжні та прогнозовані значення\")\n",
    "display(results.head(10))\n",
    "\n",
    "# 13. Висновок (коментар)\n",
    "print(\"\\nВИСНОВОК:\\n- На датасеті Diabetes LinearRegression та RandomForest показали порівнянні результати.\\n- RandomForest може давати кращу нелінійну апроксимацію, що видно з трохи вищого R2 або нижчого MSE (залежить від випадку).\\n- Вибір найбільш корельованих ознак (top-k) допоміг скоротити розмір задачі та зберегти інформативність.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa85ea",
   "metadata": {},
   "source": [
    "## Завдання 2 — Housing dataset (файл `house_price_regression_dataset.csv`)\n",
    "Кроки: 1) Зчитати CSV; 2) Аналіз; 3) Обробка пропусків, дублікатів; 4) Масштабування; 5) Розбиття; 6) Навчання Linear, RandomForest, Ridge з GridSearch; 7) Оцінка; 8) Графіки; 9) Висновки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Завдання 2 — Housing dataset з файлу 'house_price_regression_dataset.csv'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Зчитування CSV (файл має бути в /mnt/data)\n",
    "csv_path = \"/mnt/data/house_price_regression_dataset.csv\"\n",
    "print(f\"Читаємо файл: {csv_path}\")\n",
    "housing = pd.read_csv(csv_path)\n",
    "\n",
    "# 1. Перші 5 рядків\n",
    "print(\"\\nПерші 5 рядків датасету Housing:\")\n",
    "display(housing.head())\n",
    "\n",
    "# 2. Попередній аналіз: типи, розмір, пропуски\n",
    "print(\"\\nРозмір датасету:\", housing.shape)\n",
    "print(\"\\nТипи даних:\")\n",
    "print(housing.dtypes)\n",
    "print(\"\\nКількість пропусків по стовпцях:\")\n",
    "print(housing.isna().sum())\n",
    "\n",
    "# 3. Обробка пропусків: заповнюємо середнім для числових колонок\n",
    "numeric_cols = housing.select_dtypes(include=[np.number]).columns.tolist()\n",
    "housing[numeric_cols] = housing[numeric_cols].fillna(housing[numeric_cols].mean())\n",
    "\n",
    "# 4. Перевірка дублікатів\n",
    "dups = housing.duplicated().sum()\n",
    "print(f\"\\nКількість дублікатів: {dups}\")\n",
    "if dups > 0:\n",
    "    housing = housing.drop_duplicates()\n",
    "    print(\"Дублікат(и) видалено.\")\n",
    "\n",
    "# 5. Оберіть цільову змінну. Якщо в датасеті є 'Price' або 'SalePrice' - використаємо її. \n",
    "possible_targets = [c for c in housing.columns if c.lower() in ('price','saleprice','median_house_value','medianvalue','target','y')]\n",
    "print(\"\\nМожливі кандидатури на цільову змінну:\", possible_targets)\n",
    "\n",
    "if len(possible_targets) > 0:\n",
    "    target_col = possible_targets[0]\n",
    "else:\n",
    "    # якщо немає очевидного, візьмемо останню числову колонку як target (попередження)\n",
    "    numeric_cols = housing.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if len(numeric_cols) == 0:\n",
    "        raise ValueError(\"У датасеті немає числових колонок для регресії.\")\n",
    "    target_col = numeric_cols[-1]\n",
    "print(\"Використовуємо як цільову змінну:\", target_col)\n",
    "\n",
    "# Підготовка X та y\n",
    "X = housing.drop(columns=[target_col])\n",
    "y = housing[target_col]\n",
    "\n",
    "# Перетворимо категоріальні змінні (якщо є) за допомогою one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Впевненість: видаляємо колонки з NaN (якщо залишилися)\n",
    "X = X.fillna(0)\n",
    "\n",
    "# 6. Масштабування\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# 7. Розбиття\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 8. Навчання моделей: LinearRegression, RandomForest, Ridge (з GridSearch)\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=200)\n",
    "\n",
    "# Підбір гіперпараметрів для Ridge та RandomForest (GridSearch для Ridge; для RF аж ніяк не повний пошук, лише приклад)\n",
    "ridge = Ridge()\n",
    "ridge_params = {'alpha': [0.1, 1.0, 10.0, 50.0]}\n",
    "\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
    "\n",
    "# GridSearch для Ridge\n",
    "gs_ridge = GridSearchCV(ridge, ridge_params, cv=4, scoring='r2', n_jobs=-1)\n",
    "gs_ridge.fit(X_train, y_train)\n",
    "best_ridge = gs_ridge.best_estimator_\n",
    "print(\"\\nНайкращий Ridge:\", gs_ridge.best_params_)\n",
    "\n",
    "# GridSearch короткий для RF (щоб не затягувати)\n",
    "gs_rf = GridSearchCV(rf, rf_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "best_rf = gs_rf.best_estimator_\n",
    "print(\"Найкращий RF params:\", gs_rf.best_params_)\n",
    "\n",
    "# Навчання LinearRegression\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 9. Оцінка моделей\n",
    "models = {\n",
    "    'LinearRegression': lr,\n",
    "    'RandomForest': best_rf,\n",
    "    'Ridge': best_ridge\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    scores[name] = (r2, mse)\n",
    "    print(f\"\\n{name}: R2 = {r2:.4f}, MSE = {mse:.4f}\")\n",
    "\n",
    "# 10. Графіки: True vs Predicted для кожної моделі\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    y_pred = model.predict(X_test)\n",
    "    plt.subplot(1,3,i)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    mn, mx = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())\n",
    "    plt.plot([mn,mx],[mn,mx],'k--')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f'{name}\\nR2={scores[name][0]:.3f}, MSE={scores[name][1]:.3f}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 11. Вивести справжні і прогнозовані значення (перші 10)\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_test)[:10]\n",
    "    print(f\"\\n{name} — перші 10 прогнозів:\")\n",
    "    display(pd.DataFrame({'True': y_test.values[:10], 'Pred': preds}))\n",
    "\n",
    "# 12. Висновки\n",
    "print(\"\\nВИСНОВОК:\\n- Було виконано попередній аналіз та обробку датасету житла.\\n- Застосовано три моделі: LinearRegression, RandomForest (з GridSearch), Ridge (з GridSearch).\\n- Вибір найкращої моделі залежить від метрики R2 та MSE; RandomForest зазвичай дає кращі результати на складних неформальних зв'язках, але ризикує перенавчитися.\\n- Перевіряйте важливість ознак та крос-валідацію для стабільної оцінки.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e3060",
   "metadata": {},
   "source": [
    "## Загальні висновки по лабораторній роботі 3\n",
    "\n",
    "- Ми виконали попередній аналіз даних на двох наборах: Diabetes (sklearn) та Housing (з наданого CSV).\n",
    "- Продемонстровано обробку пропусків, видалення дублікатів, масштабування ознак, розбиття на трен/тест, побудову моделей та їх оцінку.\n",
    "- RandomForest зазвичай показує кращу якість на складних залежностях, тоді як лінійні моделі (LinearRegression, Ridge) легші для інтерпретації.\n",
    "- Для реального проєкту рекомендовано проводити більш ретельний відбір ознак, крос-валідацію та налаштування гіперпараметрів.\n",
    "\n",
    "### Примітки\n",
    "- Якщо файл `house_price_regression_dataset.csv` має іншу назву або іншу структуру, потрібно вказати правильну цільову змінну (стовпець з ціною).\n",
    "- В ноутбуці використано GridSearch з невеликими сітками для прикладу — за потреби розширюйте параметри.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
